{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ojmRc8E3vWt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PMnwZJnLW99",
        "outputId": "07ebffbe-640b-4289-aa25-f42446ab2d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhjjH2M6Ool9"
      },
      "outputs": [],
      "source": [
        "#Get paths for data\n",
        "\n",
        "train_data_path = '/content/drive/My Drive/food-allergy-identification/dataset/train'\n",
        "\n",
        "test_data_path = '/content/drive/My Drive/food-allergy-identification/dataset/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfiQhFtQSk5E"
      },
      "outputs": [],
      "source": [
        "# Load train and test annotations CSV files\n",
        "train_annotations = pd.read_csv('/content/drive/My Drive/food-allergy-identification/dataset/train-annotations.csv')\n",
        "test_annotations = pd.read_csv('/content/drive/My Drive/food-allergy-identification/dataset/test-annotations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxCaQim_Lkv5"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(filenames, folder_path):\n",
        "    images = []\n",
        "    for filename in filenames:\n",
        "        image = cv2.imread(folder_path + filename)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        images.append(image)\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "J4hPjjw-Nm7E",
        "outputId": "d3fc9357-3ccb-4411-aa4a-81ea56d1220c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_labels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-336fe96e8416>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encode class labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_labels_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_labels_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
          ]
        }
      ],
      "source": [
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCYuY1HRS8br"
      },
      "outputs": [],
      "source": [
        "# Define CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFLYD47eTA2N"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_encoded)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels_encoded, predicted_labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "P3UinZ-_E2RH",
        "outputId": "d25a41f9-ebb0-4c38-8dcf-0b63855a87f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "62/62 [==============================] - 46s 743ms/step - loss: -255.2208 - accuracy: 0.0189\n",
            "Test accuracy: 0.9811416920274496\n",
            "62/62 [==============================] - 53s 855ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot cast array data from dtype('<U23') to dtype('int64') according to the rule 'safe'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6ae697a2c2c1>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Display the most frequent predicted class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mbest_predicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nThe model's best-predicted class is: {label_encoder.classes_[best_predicted_class]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('<U23') to dtype('int64') according to the rule 'safe'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os  # Import os module to work with file paths\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the CSV file containing class labels\n",
        "test_annotations = pd.read_csv('/content/drive/My Drive/food-allergy-identification/dataset/test-annotations.csv')\n",
        "\n",
        "# Extract filenames and corresponding class labels\n",
        "filenames = test_annotations['filename']\n",
        "class_labels = test_annotations['class']\n",
        "\n",
        "# Define a function to load and preprocess images\n",
        "def load_and_preprocess_images(filenames, folder_path, class_labels):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename, class_label in zip(filenames, class_labels):\n",
        "        # Construct the full path to the image file\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        # Read the image using OpenCV\n",
        "        image = cv2.imread(file_path)\n",
        "        if image is None:\n",
        "            print(\"Failed to read image:\", file_path)\n",
        "            continue\n",
        "        # Resize the image to match the expected input shape of the model\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        # Optionally preprocess the image here\n",
        "        images.append(image)\n",
        "        labels.append(class_label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load and preprocess test images\n",
        "test_data_path = '/content/drive/My Drive/food-allergy-identification/dataset/test/'\n",
        "test_images, test_labels = load_and_preprocess_images(filenames, test_data_path, class_labels)\n",
        "\n",
        "# Ensure labels are properly encoded\n",
        "label_encoder = LabelEncoder()\n",
        "test_labels_encoded = label_encoder.fit_transform(test_labels)\n",
        "\n",
        "# Define CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification, so using sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels_encoded)\n",
        "print('Test accuracy:', 1 - test_acc)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.round(predictions).flatten().astype(int)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}